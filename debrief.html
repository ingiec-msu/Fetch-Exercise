<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>4.5 Lab – External Data</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="style.css">
</head>

<body class="bg-gradient-to-br from-purple-900 via-purple-700 to-indigo-900 min-h-screen flex flex-col p-4">  

  <nav class="bg-purple-950 text-white p-4 rounded-lg mb-8 shadow-lg">
    <div class="max-w-4xl mx-auto flex gap-6 justify-center">
      <a href="index.html" class="font-bold text-lg hover:text-purple-300 transition duration-300">Generator</a>
      <span class="text-purple-400">|</span>
      <a href="debrief.html" class="font-bold text-lg hover:text-purple-300 transition duration-300">Debrief</a>
    </div>
  </nav>

  <main class="bg-white rounded-lg shadow-2xl max-w-2xl w-full p-8 mx-auto">
    <h1 class="text-4xl font-bold text-center text-gray-800 mb-8">Debrief</h1>
    
    <article class="text-gray-700 leading-relaxed">
      <p class="mb-6">
        Although both the AI tools were able to help me complete this assignment, the Claude LLM was definitely more helpful and reliable than ChatGPT 4.1. Both models were given the same standard prompts, including generating JavaScript to pull random character data from the Rick and Morty API, creating a navigation bar, integrating Alpine.js for a random character button, and styling the site with Tailwind CSS. Claude handled these tasks almost flawlessly; after generating the full HTML, JavaScript, and CSS, I encountered only one minor issue related to Tailwind’s @apply directive, which Claude was able to fix immediately, resulting in fully working code that matched my expectations. In contrast, ChatGPT 4.1 required significantly more troubleshooting. Initially, the “generator” button it produced did not display any character data, even though the debrief page worked correctly. After I explicitly pointed out that the button was not producing results, ChatGPT generated code that displayed only a static character profile, which did not change on button clicks. I then had to repeatedly restate the original prompt, specifically requesting randomization via the button, before the functionality finally worked, though this introduced a new issue where two identical buttons appeared on the page. These examples show that while ChatGPT 4.1 was eventually capable of producing working code, Claude required fewer clarifications, fewer iterations, and delivered a more polished and accurate solution overall.
      </p>
    </article>
  </main>

</body>
</html>